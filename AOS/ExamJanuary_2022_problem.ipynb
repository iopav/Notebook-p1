{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af150ce",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 2021, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "* I (Benny) will visit the exam room at around 10:30 to see if there are any questions.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87c0aa",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"XXX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0803f8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0b006",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Probability warmup\n",
    "Let's say we have an exam question which consists of $20$ yes/no questions. \n",
    "From past performance of similar students, a randomly chosen student will know the correct answer to $N \\sim \\text{binom}(20,11/20)$ questions. Furthermore, we assume that the student will guess the answer with equal probability to each question they don't know the answer to, i.e. given $N$ we define $Z \\sim \\text{binom}(20-N,1/2)$ as the number of correctly guessed answers. Define $Y = N + Z$, i.e., $Y$ represents the number of total correct answers.\n",
    "\n",
    "We are interested in setting a deterministic threshold $T$, i.e., we would pass a student at threshold $T$ if $Y \\geq T$. Here $T \\in \\{0,1,2,\\ldots,20\\}$.\n",
    "\n",
    "1. [5p] For each threshold $T$, compute the probability that the student *knows* less than $10$ correct answers given that the student passed, i.e., $N < 10$. Put the answer in `problem11_probabilities` as a list.\n",
    "2. [3p] What is the smallest value of $T$ such that if $Y \\geq T$ then we are 90\\% certain that $N \\geq 10$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1990ab",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hint the PMF of N is p_N(k) where p_N is\n",
    "p = 11/20\n",
    "p_N = lambda k: binomial(20,k)*(1-p)^(20-k)*(p)^k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21189865",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 1: \n",
    "# replace XXX to represent P(N < 10) for T = [0,1,2,...,20], i.e. your answer should be a list\n",
    "# of length 21.\n",
    "problem11_probabilities = [XXX,XXX,...,XXX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf94f0",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 2: Give an integer between 0 and 20 which is the answer to 2.\n",
    "problem12_T = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1122e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 每个阈值下学生通过并且知道少于10个正确答案的概率:\n",
      "[0.249289359828412, 0.24928935982832898, 0.2492893598226106, 0.24928935963549287, 0.24928935576839342, 0.2492892991583498, 0.24928867518930262, 0.24928330207958468, 0.24924628523366035, 0.24903902630299068, 0.24808569900431449, 0.24460820014975945, 0.23494396957815247, 0.21475641513175922, 0.18267139196621007, 0.14272522447072053, 0.10227042692681917, 0.06762809950564579, 0.04166472439122744, 0.024151134340423378, 0.013287462679601613]\n",
      "\n",
      "2. 满足90%概率的最小T值:\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "# List to store the probabilities that students pass and know less than 10 correct answers for each threshold T\n",
    "# 存储问题11中每个阈值下学生通过并且知道少于10个正确答案的概率\n",
    "problem11_probabilities1 = []\n",
    "\n",
    "# Probability for N\n",
    "# 定义N的概率\n",
    "p_N = 11/20\n",
    "\n",
    "# Loop to calculate the probability for each threshold T\n",
    "# 循环计算每个阈值T的概率\n",
    "for T in range(21):\n",
    "    prob_pass_and_less_than_10 = 0\n",
    "    prob_pass = 0\n",
    "    \n",
    "    # Consider only the case where N < 10\n",
    "    # 仅考虑N < 10的情况\n",
    "    for n in range(10):\n",
    "        # Calculate the probability for N\n",
    "        # 计算N的概率\n",
    "        prob_n = binom.pmf(n, 20, p_N)\n",
    "        # Calculate P(N < 10 | Y >= T)\n",
    "        # 计算P(N < 10 | Y >= T)\n",
    "        prob_pass_and_less_than_10 += prob_n * sum([binom.pmf(k, 20-n, 0.5) for k in range(T-n, 21-n)])\n",
    "    \n",
    "    # Consider all N values\n",
    "    # 考虑所有N值的情况\n",
    "    for n in range(21):\n",
    "        # Calculate the probability for N\n",
    "        # 计算N的概率\n",
    "        prob_n = binom.pmf(n, 20, p_N)\n",
    "        prob_pass += prob_n * sum([binom.pmf(k, 20-n, 0.5) for k in range(T-n, 21-n)])\n",
    "    \n",
    "    # Calculate conditional probability: P(N < 10 | Y >= T) = P(N < 10 and Y >= T) / P(Y >= T)\n",
    "    # 计算条件概率：P(N < 10 | Y >= T) = P(N < 10 and Y >= T) / P(Y >= T)\n",
    "    conditional_prob = prob_pass_and_less_than_10 / prob_pass\n",
    "    \n",
    "    # Append the computed conditional probability to the list\n",
    "    # 将计算得到的条件概率添加到列表中\n",
    "    problem11_probabilities1.append(conditional_prob)\n",
    "\n",
    "# Assign the list of probabilities for problem 11 to the problem 11 probabilities variable\n",
    "# 将问题11的概率列表赋值给问题11的概率变量\n",
    "problem11_probabilities = problem11_probabilities1\n",
    "print(\"1. 每个阈值下学生通过并且知道少于10个正确答案的概率:\")\n",
    "print(problem11_probabilities)\n",
    "\n",
    "# Find the smallest T value such that the probability is less than or equal to 0.1\n",
    "# 找到满足概率小于等于0.1的最小T值\n",
    "T_90 = next(T for T, p in enumerate(problem11_probabilities1) if p <= 0.1)\n",
    "problem12_T = T_90\n",
    "print(\"\\n2. 满足90%概率的最小T值:\")\n",
    "print(problem12_T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba061a0a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65bbdf6",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Random variable generation and transformation\n",
    "\n",
    "The purpose of this problem is to show that you can implement your own sampler, this will be built in the following three steps:\n",
    "\n",
    "1. [2p] Implement a Linear Congruential Generator where you tested out a good combination (a large $M$ with $a,b$ satisfying the Hull-Dobell (Thm 6.8)) of parameters. Follow the instructions in the code block.\n",
    "2. [2p] Using a generator construct random numbers from the uniform $[0,1]$ distribution.\n",
    "3. [4p] Using a uniform $[0,1]$ random generator, generate samples from \n",
    "\n",
    "$$p_0(x) = \\frac{\\pi}{2}|\\sin(2\\pi x)|, \\quad x \\in [0,1] \\enspace .$$\n",
    "\n",
    "Using the **Accept-Reject** sampler (**Algorithm 1** in TFDS notes) with sampling density given by the uniform $[0,1]$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449666b",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem2_LCG(size=None, seed = 0):\n",
    "    \"\"\"\n",
    "    A linear congruential generator that generates pseudo random numbers according to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    seed : the starting point of the LCG, i.e. u0 in the notes.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    out : a list of the pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters for the LCG, these should satisfy Hull-Dobell Theorem\n",
    "    a = 16807  # Multiplier\n",
    "    M = 2**31 - 1  # Modulus\n",
    "    c = 0  # Increment\n",
    "    \n",
    "    # Initialize the state (seed)\n",
    "    state = seed\n",
    "    \n",
    "    # List to hold the pseudorandom numbers\n",
    "    out = []\n",
    "    \n",
    "    # Generate pseudorandom numbers up to the specified size\n",
    "    for _ in range(size if size is not None else 1):\n",
    "        # Update the state using the LCG formula\n",
    "        state = (a * state + c) % M\n",
    "        # Append the state to the list after normalizing\n",
    "        out.append(state / M)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7955134",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem2_uniform(generator=None, period = 1, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator and produces samples from the uniform [0,1] distribution according\n",
    "    to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of type generator(size,seed) and produces the same result as problem2_LCG, i.e. pseudo random numbers in the range {0,1,...,period-1}\n",
    "    period : the period of the generator\n",
    "    seed : the seed to be used in the generator provided\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the uniform pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate pseudo random numbers with the given generator\n",
    "    random_numbers = generator(size=size, seed=seed)\n",
    "    \n",
    "    # Normalize these numbers to the range [0,1]\n",
    "    uniform_random_numbers = [number / period for number in random_numbers]\n",
    "    \n",
    "    return uniform_random_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77a695",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def problem2_accept_reject(uniformGenerator=None, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator that produces uniform pseudo random [0,1] numbers \n",
    "    and produces samples from (pi/2)*abs(sin(x*2*pi)) using an Accept-Reject\n",
    "    sampler with the uniform distribution as the proposal distribution\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of the type generator(size,seed) that produces uniform pseudo random\n",
    "    numbers from [0,1]\n",
    "    seed : the seed to be used in the generator provided\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the pseudo random numbers with the specified distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)  # Set the seed for reproducibility\n",
    "    samples = []\n",
    "    M = np.pi / 2  # The bound for the accept-reject criterion\n",
    "\n",
    "    while len(samples) < n_iterations:\n",
    "        # Sample from the uniform distribution using the provided generator\n",
    "        x = uniformGenerator(size=1, seed=np.random.randint(0, 10000))[0]\n",
    "        \n",
    "        # Calculate the probability of accepting the sample\n",
    "        f_x = (np.pi / 2) * abs(np.sin(x * 2 * np.pi))\n",
    "        u = uniformGenerator(size=1, seed=np.random.randint(0, 10000))[0]  # Uniform random number for acceptance\n",
    "        \n",
    "        # Accept the sample with probability f(x)/(M*g(x))\n",
    "        if u < f_x / M:\n",
    "            samples.append(x)\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599292ac",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c53dd8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# If you managed to solve all three parts you can test the following code to see if it runs\n",
    "# you have to change the period to match your LCG though, this is marked as XXX.\n",
    "# It is a very good idea to check these things using the histogram function in sagemath\n",
    "# try with a larger number of samples, up to 10000 should run\n",
    "\n",
    "print(\"LCG output: %s\" % problem2_LCG(size=10, seed = 1))\n",
    "\n",
    "period =  2**31 - 1\n",
    "\n",
    "print(\"Uniform sampler %s\" % problem2_uniform(generator=problem2_LCG, period = period, size=10, seed=1))\n",
    "\n",
    "uniform_sampler = lambda size,seed: problem2_uniform(generator=problem2_LCG, period = period, size=size, seed=seed)\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem2_accept_reject(uniformGenerator = uniform_sampler,n_iterations=20,seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1a8c1",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# If however you did not manage to implement either part 1 or part 2 but still want to check part 3, you can run the code below\n",
    "\n",
    "def testUniformGenerator(size,seed):\n",
    "    set_random_seed(seed)\n",
    "    \n",
    "    return [random() for s in range(size)]\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem2_accept_reject(uniformGenerator=testUniformGenerator, n_iterations=20, seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9848ffea",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7b29f",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Concentration of measure\n",
    "\n",
    "As you recall, we said that concentration of measure was simply the phenomenon where we expect that the probability of a large deviation of some quantity becoming smaller as we observe more samples: [0.4 points per correct answer]\n",
    "\n",
    "1. Which of the following will exponentially concentrate, i.e. for some $C_1,C_2,C_3,C_4 $ \n",
    "$$\n",
    "    P(Z - \\mathbb{E}[Z] \\geq \\epsilon) \\leq C_1 e^{-C_2 n \\epsilon^2} \\wedge C_3 e^{-C_4 n (\\epsilon+1)} \\enspace .\n",
    "$$\n",
    "\n",
    "    1. The empirical mean of i.i.d. sub-Gaussian random variables?\n",
    "    2. The empirical mean of i.i.d. sub-Exponential random variables?\n",
    "    3. The empirical mean of i.i.d. random variables with finite variance?\n",
    "    4. The empirical variance of i.i.d. random variables with finite variance?\n",
    "    5. The empirical variance of i.i.d. sub-Gaussian random variables?\n",
    "    6. The empirical variance of i.i.d. sub-Exponential random variables?\n",
    "    7. The empirical third moment of i.i.d. sub-Gaussian random variables?\n",
    "    8. The empirical fourth moment of i.i.d. sub-Gaussian random variables?\n",
    "    9. The empirical mean of i.i.d. deterministic random variables?\n",
    "    10. The empirical tenth moment of i.i.d. Bernoulli random variables?\n",
    "\n",
    "2. Which of the above will concentrate in the weaker sense, that for some $C_1$\n",
    "$$\n",
    "    P(Z - \\mathbb{E}[Z] \\geq \\epsilon) \\leq \\frac{C_1}{n \\epsilon^2}?\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593fba5a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answers to part 1, which of the alternatives exponentially concentrate, answer as a list\n",
    "# i.e. [1,4,5] that is example 1, 4, and 5 concentrate\n",
    "problem3_answer_1 = [2,4,5,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11def9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Answers to part 2, which of the alternatives concentrate in the weaker sense, answer as a list\n",
    "# i.e. [1,4,5] that is example 1, 4, and 5 concentrate\n",
    "problem3_answer_2 = [3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6876a583",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 4\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c6266e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## SMS spam filtering [8p]\n",
    "\n",
    "In the following problem we will explore SMS spam texts. The dataset is the `SMS Spam Collection Dataset` and we have provided for you a way to load the data. If you run the appropriate cell below, the result will be in the `spam_no_spam` variable. The result is a `list` of `tuples` with the first position in the tuple being the SMS text and the second being a flag `0 = not spam` and `1 = spam`.\n",
    "\n",
    "1. [3p] Let $X$ be the random variable that represents each SMS text (an entry in the list), and let $Y$ represent whether text is spam or not i.e. $Y \\in \\{0,1\\}$. Thus $\\mathbb{P}(Y = 1)$ is the probability that we get a spam. The goal is to estimate:\n",
    "$$\n",
    "    \\mathbb{P}(Y = 1 | \\text{\"free\" or \"prize\" is in } X) \\enspace .\n",
    "$$\n",
    "That is, the probability that the SMS is spam given that \"free\" or \"prize\" occurs in the SMS. \n",
    "Hint: it is good to remove the upper/lower case of words so that we can also find \"Free\" and \"Prize\"; this can be done with `text.lower()` if `text` a string.\n",
    "2. [3p] Provide a \"90\\%\" interval of confidence around the true probability. I.e. use the Hoeffding inequality to obtain for your estimate $\\hat P$ of the above quantity. Find $l > 0$ such that the following holds:\n",
    "$$\n",
    "    \\mathbb{P}(\\hat P - l \\leq \\mathbb{E}[\\hat P] \\leq \\hat P + l) \\geq 0.9 \\enspace .\n",
    "$$\n",
    "3. [2p] Repeat the two exercises above for \"free\" appearing twice in the SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86b4ce",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run this cell to get the SMS text data\n",
    "from exam_extras import load_sms\n",
    "spam_no_spam = load_sms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0f279",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the estimate for part 1 here (should be a number between 0 and 1)\n",
    "# Part 1\n",
    "# Count the number of spam texts and texts with \"free\" or \"prize\"\n",
    "import numpy as np\n",
    "import math\n",
    "spam_count = 0\n",
    "free_prize_count = 0\n",
    "py1=0\n",
    "pfreeinx=0\n",
    "freeinxandy1=0\n",
    "for text, flag in spam_no_spam:\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # Check if spam\n",
    "    if flag == 1:\n",
    "        spam_count += 1\n",
    "    # Check if contains \"free\" or \"prize\"\n",
    "    if \"free\" in text or \"prize\" in text:\n",
    "        free_prize_count += 1\n",
    "        # Check if both spam and contains \"free\" or \"prize\"\n",
    "        if flag == 1:\n",
    "            freeinxandy1 += 1\n",
    "\n",
    "        \n",
    "problem4_hatP = freeinxandy1/free_prize_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72cc4e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the calculated l from part 2 here\n",
    "\n",
    "n=free_prize_count\n",
    "delta = 0.1\n",
    "problem4_l =np.sqrt(np.log(0.1/2)/(-2*n))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100e5ea",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the estimate for hatP for the double free question in part 3 here (should be a number between 0 and 1)\n",
    "# Part 3\n",
    "# Count the number of texts with 2 \"free\" \n",
    "free_twice_count = 0\n",
    "free_twice_countandy1 = 0\n",
    "for text, flag in spam_no_spam:\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # Check if contains \"free\" twice\n",
    "    if text.count(\"free\") == 2:\n",
    "        free_twice_count += 1\n",
    "        # Check if both spam and contains \"free\" twice\n",
    "        if flag == 1:\n",
    "            free_twice_countandy1 += 1\n",
    "\n",
    "\n",
    "problem4_hatP2 = free_twice_countandy1/free_twice_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19289d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill in the estimate for l for the double free question in part 3 here\n",
    "n=free_twice_count\n",
    "delta = 0.1\n",
    "problem4_l2 =np.sqrt(np.log(0.1/2)/(-2*n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7d777",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 5\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e686c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Markovian travel\n",
    "\n",
    "The dataset `Travel Dataset - Datathon 2019` is a simulated dataset designed to mimic real corporate travel systems -- focusing on flights and hotels. The file is at `data/flights.csv` in the same folder as `Exam.ipynb`, i.e. you can use the path `data/flights.csv` from the notebook to access the file.\n",
    "\n",
    "1. [2p] In the first code-box \n",
    "    1. Load the csv from file `data/flights.csv`\n",
    "    2. Fill in the value of the variables as specified by their names.\n",
    "2. [2p] In the second code-box your goal is to estimate a Markov chain transition matrix for the travels of these users. For example, if we enumerate the cities according to alphabetical order, the first city `'Aracaju (SE)'` would correspond to $0$. Each row of the file corresponds to one flight, i.e. it has a starting city and an ending city. We model this as a stationary Markov chain, i.e. each user's travel trajectory is a realization of the Markov chain, $X_t$. Here, $X_t$ is the current city the user is at, at step $t$, and $X_{t+1}$ is the city the user travels to at the next time step. This means that to each row in the file there is a corresponding pair $(X_{t},X_{t+1})$. The stationarity assumption gives that for all $t$ there is a transition density $p$ such that $P(X_{t+1} = y | X_t = x) = p(x,y)$ (for all $x,y$). The transition matrix should be `n_cities` x `n_citites` in size.\n",
    "3. [2p] Use the transition matrix to compute out the stationary distribution.\n",
    "4. [2p] Given that we start in 'Aracaju (SE)' what is the probability that after 3 steps we will be back in 'Aracaju (SE)'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723adcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/flights.csv\")\n",
    "number_of_cities = data['from'].nunique()+data['to'].nunique()\n",
    "number_of_userCodes = data['userCode'].nunique()\n",
    "number_of_observations = len(data)\n",
    "#data\n",
    "print(number_of_cities)\n",
    "print(number_of_userCodes)\n",
    "print(number_of_observations)\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Extracting the cities and transitions\n",
    "cities = data['from'].tolist() + data['to'].tolist()\n",
    "transitions = list(zip(data['from'], data['to']))\n",
    "\n",
    "# Count the different transitions\n",
    "transition_counts = Counter(transitions)\n",
    "\n",
    "# Creating dictionaries for city to index and index to city mappings\n",
    "unique_cities = sorted(set(cities))\n",
    "cityToIndex = {city: i for i, city in enumerate(unique_cities)}\n",
    "indexToCity = {i: city for i, city in enumerate(unique_cities)}\n",
    "n_cities = len(unique_cities)\n",
    "\n",
    "# Initialize the transition matrix\n",
    "transition_matrix = np.zeros((n_cities, n_cities))\n",
    "\n",
    "# Populate the transition matrix\n",
    "for (start, end), count in transition_counts.items():\n",
    "    start_index = cityToIndex[start]\n",
    "    end_index = cityToIndex[end]\n",
    "    transition_matrix[start_index, end_index] = count\n",
    "\n",
    "# Convert counts to probabilities\n",
    "for i in range(n_cities):\n",
    "    row_sum = np.sum(transition_matrix[i, :])\n",
    "    if row_sum > 0:\n",
    "        transition_matrix[i, :] /= row_sum\n",
    "\n",
    "# Ensure there are no NaNs in the transition matrix\n",
    "transition_matrix = np.nan_to_num(transition_matrix)\n",
    "# This should be a numpy array of length n_cities which sums to 1 and is all positive\n",
    "# Compute the stationary distribution\n",
    "eigenvalues, eigenvectors = np.linalg.eig(transition_matrix.T)\n",
    "stationary_distribution_index = np.argmin(np.abs(eigenvalues - 1))\n",
    "stationary_distribution = np.real(eigenvectors[:, stationary_distribution_index]).astype(float)\n",
    "\n",
    "# Normalize the stationary distribution\n",
    "stationary_distribution /= stationary_distribution.sum()\n",
    "\n",
    "# Ensuring the distribution is valid (non-negative and sums to 1)\n",
    "stationary_distribution = np.clip(stationary_distribution, 0, None)\n",
    "stationary_distribution /= stationary_distribution.sum()\n",
    "\n",
    "#stationary_distribution.shape, stationary_distribution[:5]  # Displaying the shape and a part of the distribution\n",
    "\n",
    "stationary_distribution_problem5 = stationary_distribution\n",
    "# Compute the return probability for part 3 of problem 5\n",
    "# Finding the index for 'Aracaju (SE)'\n",
    "aracaju_index = cityToIndex['Aracaju (SE)']\n",
    "\n",
    "# Compute the transition matrix raised to the power of 3\n",
    "transition_matrix_3_steps = np.linalg.matrix_power(transition_matrix, 3)\n",
    "\n",
    "# Probability of being back in 'Aracaju (SE)' after 3 steps\n",
    "return_probability_problem5 = transition_matrix_3_steps[aracaju_index, aracaju_index]\n",
    "return_probability_problem5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ez\n",
    "# Load the csv file data/flights.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "flights = pd.read_csv(\"data/flights.csv\")\n",
    "\n",
    "# Part 1: Fill in the values of the variables\n",
    "number_of_cities = len(flights[\"origin\"].unique())\n",
    "number_of_userCodes = len(flights[\"userCodes\"].unique())\n",
    "number_of_observations = len(flights[\"observations\"].unique())  # Corrected the variable name\n",
    "\n",
    "# This function creates a frequency dictionary from a list of data\n",
    "def makeFreqDict(myDataList):\n",
    "    '''Make a frequency mapping out of a list of data.\n",
    "    \n",
    "    Param myDataList: a list of data.\n",
    "    Return: a dictionary mapping each unique data value to its frequency count.'''\n",
    "    \n",
    "    freqDict = {}  # start with an empty dictionary\n",
    "\n",
    "    for res in myDataList:\n",
    "        if res in freqDict:  # the data value already exists as a key\n",
    "            freqDict[res] += 1  # add 1 to the count\n",
    "        else:  # the data value does not exist as a key value\n",
    "            freqDict[res] = 1  # add a new key-value pair for this new data value, frequency 1\n",
    "\n",
    "    return freqDict  # return the dictionary created\n",
    "\n",
    "# Part 2: Estimate a Markov chain transition matrix\n",
    "cities = flights[\"origin\"].tolist()  # A list of all the cities\n",
    "unique_cities = sorted(set(cities))  # The unique cities\n",
    "n_cities = len(unique_cities)  # The number of unique cities\n",
    "\n",
    "# Count the different transitions\n",
    "transitions = list(zip(cities[:-1], cities[1:]))  # A list of all transitions in the data\n",
    "transition_counts = makeFreqDict(transitions)  # A dictionary that counts the number of each transition\n",
    "\n",
    "# Create dictionaries for mapping indices to cities and vice versa\n",
    "indexToCity = dict(enumerate(unique_cities))\n",
    "cityToIndex = {v: k for k, v in indexToCity.items()}\n",
    "\n",
    "# Part 3: Find the maximum likelihood estimate of the transition matrix\n",
    "transition_matrix = np.zeros((n_cities, n_cities))\n",
    "\n",
    "for transition, count in transition_counts.items():\n",
    "    from_city, to_city = transition\n",
    "    transition_matrix[cityToIndex[from_city], cityToIndex[to_city]] = count\n",
    "\n",
    "# Normalize the transition matrix to get probabilities\n",
    "transition_matrix = transition_matrix / transition_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Part 4: Compute the stationary distribution\n",
    "eigenvalues, eigenvectors = np.linalg.eig(transition_matrix.T)\n",
    "stationary_distribution_problem5 = eigenvectors[:, np.argmax(np.isclose(eigenvalues, 1))]  # Eigenvector corresponding to eigenvalue 1\n",
    "\n",
    "# Normalize the stationary distribution\n",
    "stationary_distribution_problem5 /= stationary_distribution_problem5.sum()\n",
    "\n",
    "# Part 5: Compute the return probability after 3 steps\n",
    "return_probability_problem5 = np.dot(stationary_distribution_problem5, np.linalg.matrix_power(transition_matrix, 3))\n",
    "\n",
    "# Display the results\n",
    "print(\"Number of cities:\", number_of_cities)\n",
    "print(\"Number of user codes:\", number_of_userCodes)\n",
    "print(\"Number of observations:\", number_of_observations)\n",
    "print(\"Transition Matrix:\")\n",
    "print(transition_matrix)\n",
    "print(\"Stationary Distribution:\")\n",
    "print(stationary_distribution_problem5)\n",
    "print(\"Return Probability after 3 steps:\", return_probability_problem5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50be9c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "#load the csv file data/flights.csv\n",
    "import pandas as pd\n",
    "flights = pd.read_csv(\"data/flights.csv\")\n",
    "\n",
    "number_of_cities = len(flights[\"origin\"].unique())\n",
    "number_of_userCodes = len(flights[\"userCodes\"].unique())\n",
    "number_of_observations = len(flights[\"obersevations\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2cd78",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This is a very useful function that you can use for part 2. You have seen this before when parsing the\n",
    "# pride and prejudice book.\n",
    "\n",
    "def makeFreqDict(myDataList):\n",
    "    '''Make a frequency mapping out of a list of data.\n",
    "\n",
    "    Param myDataList, a list of data.\n",
    "    Return a dictionary mapping each unique data value to its frequency count.'''\n",
    "\n",
    "    freqDict = {} # start with an empty dictionary\n",
    "\n",
    "    for res in myDataList:\n",
    "        if res in freqDict: # the data value already exists as a key\n",
    "                freqDict[res] = freqDict[res] + 1 # add 1 to the count using sage integers\n",
    "        else: # the data value does not exist as a key value\n",
    "            freqDict[res] = 1 # add a new key-value pair for this new data value, frequency 1\n",
    "\n",
    "    return freqDict # return the dictionary created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfee1fd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "cities = flights[\"origin\"].tolist() # A list of all the cities\n",
    "unique_cities = sorted(set(cities)) # The unique cities\n",
    "n_cities = len(unique_cities) # The number of unique citites\n",
    "\n",
    "# Count the different transitions\n",
    "transitions = \n",
    "# A list containing tuples ex: ('Aracaju (SE)','Rio de Janeiro (RJ)') of all transitions in the text\n",
    "transition_counts = \n",
    "# A dictionary that counts the number of each transition \n",
    "# ex: ('Aracaju (SE)','Rio de Janeiro (RJ)'):4\n",
    "indexToCity =  # A dictionary that maps the n-1 number to the n:th unique_city,\n",
    "# ex: 0:'Aracaju (SE)'\n",
    "cityToIndex =  # The inverse function of indexToWord, \n",
    "# ex: 'Aracaju (SE)':0\n",
    "\n",
    "# Part 3, finding the maximum likelihood estimate of the transition matrix\n",
    "\n",
    "transition_matrix = \n",
    "# a numpy array of size (n_cities,n_cities)\n",
    "\n",
    "# The transition matrix should be ordered in such a way that\n",
    "# p_{'Aracaju (SE)','Rio de Janeiro (RJ)'} = transition_matrix[cityToIndex['Aracaju (SE)'],cityToIndex['Rio de Janeiro (RJ)']]\n",
    "# and represents the probability of travelling Aracaju (SE)->Rio de Janeiro (RJ)\n",
    "\n",
    "# Make sure that the transition_matrix does not contain np.nan from division by zero for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2053f5d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This should be a numpy array of length n_cities which sums to 1 and is all positive\n",
    "\n",
    "stationary_distribution_problem5 = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b10afd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute the return probability for part 3 of problem 5\n",
    "\n",
    "return_probability_problem5 = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31083a19",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 5\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51e7c9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "5",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# Once you have created all your functions, you can make a small test here to see\n",
    "# what would be generated from your model.\n",
    "import numpy as np\n",
    "\n",
    "start = np.zeros(shape=(n_cities,1))\n",
    "start[cityToIndex['Aracaju (SE)'],0] = 1\n",
    "\n",
    "current_pos = start\n",
    "for i in range(10):\n",
    "    random_word_index = np.random.choice(range(n_cities),p=current_pos.reshape(-1))\n",
    "    current_pos = np.zeros_like(start)\n",
    "    current_pos[random_word_index] = 1\n",
    "    print(indexToCity[random_word_index],end='->')\n",
    "    current_pos = (current_pos.T@transition_matrix).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d372c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 6\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb4571e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Black box testing\n",
    "\n",
    "In the following problem we will continue with our SMS spam / nospam data. This time we will try to approach the problem as a pattern recognition problem. For this particular problem I have provided you with everything -- data is prepared, split into train-test sets and a black-box model has been fitted on the training data and predicted on the test data. Your goal is to calculate test metrics and provide guarantees for each metric.\n",
    "\n",
    "1. [2p] Compute precision for class 1 (see notes 8.3.2 for definition), then provide an interval using Hoeffding's inequality for a 95\\% confidence.\n",
    "2. [2p] Compute recall for class 1(see notes 8.3.2 for definition), then provide an interval using Hoeffding's inequality for a 95\\% interval.\n",
    "3. [2p] Compute accuracy (0-1 loss), then provide an interval using Hoeffding's inequality for a 95\\% interval.\n",
    "4. [2p] If we would have used a classifier with VC-dimension 3, would we have obtained a smaller interval for accuracy by using all data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f59dcd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# The code below will load data, split the data into train and test, and run a \"black box\" algorithm on it\n",
    "# the result of the \"black box\" is stored in predictions_problem6, the true values will be stored in\n",
    "# Y_test_problem6\n",
    "import exam_extras\n",
    "from exam_extras import load_sms_problem6\n",
    "X_problem6, Y_problem6 = load_sms_problem6()\n",
    "\n",
    "X_train_problem6, X_test_problem6, Y_train_problem6, Y_test_problem6 = exam_extras.train_test_split(X_problem6, Y_problem6)\n",
    "predictions_problem6 = exam_extras.knn_predictions(X_train_problem6, Y_train_problem6, X_test_problem6, k=4)\n",
    "\n",
    "# Compute the precision of predictions_problem6 with respect to Y_test_problem6\n",
    "problem6_precision = sum((predictions_problem6 == 1) & (Y_test_problem6 == 1)) / sum(predictions_problem6 == 1)\n",
    "\n",
    "# Compute the interval length l of precision of predictions_problem6 with respect to Y_test_problem6, with the same definition of l as in problem 4\n",
    "n = len(Y_test_problem6)\n",
    "problem6_precision_l = np.sqrt((1 / (2 * n)) * np.log(2 / 0.05))\n",
    "\n",
    "# Repeat the same procedure but for recall\n",
    "problem6_recall = sum((predictions_problem6 == 1) & (Y_test_problem6 == 1)) / sum(Y_test_problem6 == 1)\n",
    "\n",
    "problem6_recall_l = np.sqrt((1 / (2 * n)) * np.log(2 / 0.05))\n",
    "\n",
    "# Repeat the same procedure but for accuracy or 0-1 loss\n",
    "problem6_accuracy = sum(predictions_problem6 == Y_test_problem6) / n\n",
    "\n",
    "problem6_accuracy_l = np.sqrt((1 / (2 * n)) * np.log(2 / 0.05))\n",
    "\n",
    "# Below you will calculate the interval parameter l for a classifier running on all data with a VC dimension of 3\n",
    "# put the value in problem6_VC_l and answer problem_VC_smaller as True if the interval is smaller than the test-accuracy above\n",
    "# if not answer False. Make sure you replace XXX with something even if you only answer one of them.\n",
    "\n",
    "# Assuming VC-dimension (d_vc) is 3\n",
    "d_vc = 3\n",
    "problem6_VC_l = np.sqrt((8 / n) * np.log((4 * ((2 * n) ** d_vc) + 1) / 0.05))\n",
    "problem6_VC_smaller = problem6_VC_l < problem6_accuracy_l  # True if the VC interval is smaller\n",
    "\n",
    "# Display the results\n",
    "print(\"Precision:\", problem6_precision)\n",
    "print(\"Precision Interval Length (Hoeffding):\", problem6_precision_l)\n",
    "print(\"Recall:\", problem6_recall)\n",
    "print(\"Recall Interval Length (Hoeffding):\", problem6_recall_l)\n",
    "print(\"Accuracy:\", problem6_accuracy)\n",
    "print(\"Accuracy Interval Length (Hoeffding):\", problem6_accuracy_l)\n",
    "print(\"VC Interval Length:\", problem6_VC_l)\n",
    "print(\"Is VC Interval Smaller?\", problem6_VC_smaller)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8148a9",
   "metadata": {
    "deletable": false,
    "jupyter": {
     "source_hidden": false
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# The code below will load data, split the data into train and test and run a \"black box\" algorithm on it\n",
    "# the result of the \"black box\" is stored in predictions_problem6, the true values will be stored in\n",
    "# Y_test_problem6\n",
    "import exam_extras\n",
    "from exam_extras import load_sms_problem6\n",
    "X_problem6, Y_problem6 = load_sms_problem6()\n",
    "\n",
    "X_train_problem6,X_test_problem6,Y_train_problem6,Y_test_problem6 = exam_extras.train_test_split(X_problem6,Y_problem6)\n",
    "predictions_problem6 = exam_extras.knn_predictions(X_train_problem6,Y_train_problem6,X_test_problem6,k=4)\n",
    "\n",
    "\n",
    "# Compute the precision of predictions_problem6 with respect to Y_test_problem6\n",
    "problem6_precision = XXX\n",
    "\n",
    "# Compute the interval length l of precision of predictions_problem6 with respect to Y_test_problem6, with the same definition of l as in problem 4\n",
    "problem6_precision_l = XXX\n",
    "\n",
    "# Repeat the same procedure but for recall\n",
    "problem6_recall = XXX\n",
    "\n",
    "problem6_recall_l = XXX\n",
    "\n",
    "# Repeat the same procedure but for accuracy or 0-1 loss\n",
    "problem6_accuracy = XXX\n",
    "\n",
    "problem6_accuracy_l = XXX\n",
    "\n",
    "# Below you will calculate the interval parameter l for a classifier running on all data with a VC dimension of 3\n",
    "# put the value in problem6_VC_l and answer problem_VC_smaller as True if the interval is smaller than the test-accuracy above\n",
    "# if not answer False. Make sure you replace XXX with something even if you only answer one of them.\n",
    "problem6_VC_l = XXX # number\n",
    "problem6_VC_smaller = XXX #True / False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2022",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
