{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 2 for Course 1MS041\n",
    "Make         sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline         and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "A courier company operates a fleet of delivery trucks that make deliveries to different parts of the city. The trucks are equipped with GPS tracking devices that record the location of each truck at regular intervals. The locations are divided into three regions: downtown, the suburbs, and the countryside. The following table shows the probabilities of a truck transitioning between these regions at each time step:\n",
    "\n",
    "| Current region | Probability of transitioning to downtown | Probability of transitioning to the suburbs | Probability of transitioning to the countryside |\n",
    "|----------------|--------------------------------------------|-----------------------------------------------|------------------------------------------------|\n",
    "| Downtown       | 0.3                                      | 0.4                                           | 0.3                                            |\n",
    "| Suburbs        | 0.2                                      | 0.5                                           | 0.3                                            |\n",
    "| Countryside    | 0.4                                      | 0.3                                           | 0.3                                            |\n",
    "\n",
    "1. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region after two time steps? [1.5p]\n",
    "2. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region **the first time** after two time steps? [1.5p]\n",
    "3. Is this Markov chain irreducible? [1.5p]\n",
    "4. What is the stationary distribution? [1.5p]\n",
    "5. Advanced question: What is the expected number of steps until the first time one enters the downtown region having started in the suburbs region. Hint: to get within 1 decimal point, it is enough to compute the probabilities for hitting times below 30. [2p]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "import numpy as np\n",
    "P=np.array([\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.2, 0.5, 0.3],\n",
    "    [0.4, 0.3, 0.3]\n",
    "])\n",
    "\n",
    "two_step_transition = np.linalg.matrix_power(P,2)#这里是求P的2次方，即两步转移概率矩阵\n",
    "prob_sub_to_downtown = two_step_transition[1,0]#这里是求从subway到downtown的概率，即第二行第一列的元素\n",
    "\n",
    "two_step_transition\n",
    "prob_sub_to_downtown\n",
    "problem1_p1 = prob_sub_to_downtown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "import numpy as np\n",
    "P=np.array([\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.2, 0.5, 0.3],\n",
    "    [0.4, 0.3, 0.3]\n",
    "])\n",
    "\n",
    "prob_sub_sub_downtown = P[1][1]*P[1][0]\n",
    "prob_sub_country_downtown = P[1][2]*P[2][0]\n",
    "prob_total = prob_sub_sub_downtown + prob_sub_country_downtown\n",
    "\n",
    "prob_total\n",
    "\n",
    "problem1_p2 = prob_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Fill in the answer to part 3 below as a boolean\n",
    "problem1_irreducible = True\n",
    "# why this markov chain is irreducible? \n",
    "# because it is a strongly connected graph, \n",
    "# which means that there is a path from any state to any other state.\n",
    "# not go back to the original state at probability 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "import numpy as np\n",
    "P=np.array([\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.2, 0.5, 0.3],\n",
    "    [0.4, 0.3, 0.3]\n",
    "])\n",
    "#计算P的转置矩阵的特征值和特征向量\n",
    "eigenvalue, eigenvectors = np.linalg.eig(P.T)\n",
    "#找到特征值为1的特征向量\n",
    "close_to_one = np.isclose(eigenvalue,1)\n",
    "relevant_eigenvectors = eigenvectors[:,close_to_one]\n",
    "#计算特征向量的实部\n",
    "stationary_vectors = np.real(relevant_eigenvectors.flatten())\n",
    "#计算稳态分布\n",
    "#归一化\n",
    "stationary_distribution = stationary_vectors/stationary_vectors.sum()#这里是将特征向量的实部除以特征向量的和，即得到稳态分布\n",
    "\n",
    "problem1_stationary = stationary_distribution\n",
    "# Fill in the answer to part 4 below\n",
    "# the answer should be a numpy array of length 3\n",
    "# make sure that the entries sums to 1!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算马尔可夫链的稳态分布通常涉及解线性方程组或者使用马尔可夫链的收敛性质。以下是两种常见的计算方法：\n",
    "\n",
    "1. **转移概率矩阵的特征向量法：**\n",
    "\n",
    "   对于马尔可夫链的转移概率矩阵 \\(P\\)，稳态分布 \\( \\pi \\) 是其特征值为1的左特征向量（normalized，即元素和为1）所对应的特征向量。具体步骤如下：\n",
    "\n",
    "   a. 计算转移概率矩阵 \\(P\\) 的特征值和特征向量。\n",
    "\n",
    "   b. 选择特征值为1的左特征向量，并将其进行归一化，使得其元素之和为1。\n",
    "\n",
    "   这样得到的归一化的特征向量就是稳态分布 \\( \\pi \\)。\n",
    "\n",
    "2. **迭代法：**\n",
    "\n",
    "   可以通过迭代法逼近稳态分布。具体步骤如下：\n",
    "\n",
    "   a. 随机选择一个初始概率分布向量 \\( \\pi^{(0)} \\)。\n",
    "\n",
    "   b. 迭代计算 \\( \\pi^{(t+1)} = \\pi^{(t)} \\cdot P \\)，其中 \\( P \\) 是转移概率矩阵。\n",
    "\n",
    "   c. 当 \\( \\pi^{(t+1)} \\) 和 \\( \\pi^{(t)} \\) 足够接近时，即 \\( \\| \\pi^{(t+1)} - \\pi^{(t)} \\| < \\epsilon \\)，其中 \\( \\epsilon \\) 是一个小的阈值，可以认为找到了稳态分布。\n",
    "\n",
    "这两种方法都有其适用范围和注意事项。特征向量法适用于特征值和特征向量易于计算的情况，而迭代法则是一种通用的数值逼近方法。选择适合具体问题的方法需要考虑问题的性质和计算效率。在实际应用中，有时候也可以利用计算工具如Python的NumPy库或专业数学软件来进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28888889, 0.41111111, 0.3       ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem1_stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.846153846153845"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = 0\n",
    "ec = 0\n",
    "p_ss = 0.5\n",
    "p_sc = 0.3\n",
    "p_cs = 0.3\n",
    "\n",
    "# We can increase the number of iterations for more accuracy\n",
    "# Here, 1000 iterations should be more than sufficient for convergence.\n",
    "for _ in range(1000):\n",
    "    new_es = 1 + p_ss * es + p_sc * ec\n",
    "    new_ec = 1 + p_cs * es + p_sc * ec\n",
    "    es, ec = new_es, new_ec\n",
    "\n",
    "\n",
    "problem1_ET=es\n",
    "problem1_ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "A healthcare organization is interested in understanding the relationship between the number of visits to the doctors office and certain patient characteristics. \n",
    "They have collected data on the number of visits (for a year) for a sample of patients and have included the following variables\n",
    "\n",
    "* ofp : number of physician office visits\n",
    "* ofnp : number of nonphysician office visits\n",
    "* opp : number of physician outpatient visits\n",
    "* opnp : number of nonphysician outpatient visits\n",
    "* emr : number of emergency room visits\n",
    "* hosp : number of hospitalizations\n",
    "* exclhlth : the person is of excellent health (self-perceived)\n",
    "* poorhealth : the person is of poor health (self-perceived)\n",
    "* numchron : number of chronic conditions\n",
    "* adldiff : the person has a condition that limits activities of daily living ?\n",
    "* noreast : the person is from the north east region\n",
    "* midwest : the person is from the midwest region\n",
    "* west : the person is from the west region\n",
    "* age : age in years (divided by 10)\n",
    "* male : is the person male ?\n",
    "* married : is the person married ?\n",
    "* school : number of years of education\n",
    "* faminc : family income in 10000$\n",
    "* employed : is the person employed ?\n",
    "* privins : is the person covered by private health insurance?\n",
    "* medicaid : is the person covered by medicaid ?\n",
    "\n",
    "Decide which patient features are resonable to use to predict the target \"number of physician office visits\". Hint: should we really use the \"ofnp\" etc variables?\n",
    "\n",
    "Since the target variable is counts, a reasonable loss function is to consider the target variable as Poisson distributed where the parameter follows $\\lambda = \\exp(\\alpha \\cdot x + \\beta)$ where $\\alpha$ is a vector (slope) and $\\beta$ is a number (intercept). That is, the parameter is the exponential of a linear function. The reason we chose this as our parameter, is that it is always positive which is when the Poisson distribution is defined. To be specific we make the following assumption about our conditional density of $Y \\mid X$,\n",
    "$$\n",
    "    f_{Y \\mid X} (y,x) = \\frac{\\lambda^{y} e^{-\\lambda}}{y !}, \\quad \\lambda(x) = \\exp(\\alpha \\cdot x + \\beta).\n",
    "$$\n",
    "\n",
    "Recall from the lecture notes, (4.2) that in this case we should consider the log-loss (entropy) and that according to (4.2.1 Maximum Likelihood and regression) we can consider the conditional log-likelihood. Follow the steps of Example 1 and Example 2 in section (4.2) to derive the loss that needs to be minimized.\n",
    "\n",
    "Hint: when taking the log of the conditional density you will find that the term that contains the $y!$ does not depend on $\\lambda$ and as such does not depend on $\\alpha,\\beta$, it can thus be discarded. This will be essential due to numerical issues with factorials.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Load the file `data/visits_clean.csv`, follow the instructions in the code cell of how this should happen [1.5p]\n",
    "2. Create the `problem2_X` and the `problem2_y` as numpy arrays with `problem2_X` being the features and `problem2_y` being the target. Do the standard train-test split with 80% training data and 20% testing data. Store these in the variables defined in the cells. [1.5p]\n",
    "3. Implement $loss$ inside the class `PoissonRegression` by writing down the loss to be minimized, I have provided a formula for the $\\lambda$ that you can use. [1.5p]\n",
    "4. Now use the `PoissonRegression` class to train a Poisson regression model on the training data. [1.5p]\n",
    "5. Compute the mean absolute error of your prediction on the test set and use Hoeffdings inequality to produce a 95\\% confidence interval for the mean absolute error. We can make the assumption that the error is bounded by 70 for simplicity. [2p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "correct_feature = [\"exclhlth\", \"poorhlth\", \"numchron\", \"adldiff\", \"age\", \"male\", \"married\", \"school\", \"faminc\"\\\n",
    "    , \"employed\", \"privins\", \"medicaid\"]\n",
    "\n",
    "# Read the header from the CSV file\n",
    "problem2_header = []\n",
    "with open(r\"data/visits_clean.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    problem2_header = next(reader)[0].strip().split()  # Adjust the split character based on your CSV file's delimiter\n",
    "\n",
    "# Check if correct_feature items are in problem2_header\n",
    "feature_index = [problem2_header.index(x) for x in correct_feature if x in problem2_header]\n",
    "\n",
    "# If some features are not found, you may want to handle this scenario\n",
    "if len(feature_index) != len(correct_feature):\n",
    "    print(\"Warning: Some features were not found in the header.\")\n",
    "\n",
    "# Load the data using numpy.genfromtxt\n",
    "problem2_data = np.genfromtxt(r\"data/visits_clean.csv\", dtype=float, delimiter=\" \", skip_header=1, usecols=feature_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "problem2_X = problem2_data[:, :-1]  # All columns except the last one\n",
    "problem2_y = problem2_data[:, -1]   # Only the last column\n",
    "\n",
    "# Shuffle indices to split the data randomly\n",
    "indices = np.arange(problem2_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Calculate the number of training samples, rounding up to the nearest integer\n",
    "train_size = int(np.ceil(0.8 * len(indices)))\n",
    "\n",
    "# Split indices into training and test sets\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "# Split the data into training and test sets using the shuffled indices\n",
    "problem2_X_train = problem2_X[train_indices]\n",
    "problem2_y_train = problem2_y[train_indices]\n",
    "problem2_X_test = problem2_X[test_indices]\n",
    "problem2_y_test = problem2_y[test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "class PoissonRegression(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    def loss(self, X, Y, coeffs):\n",
    "       \n",
    "        lam = np.exp(np.dot(X, coeffs[:-1]) + coeffs[-1])\n",
    "        neg_log_likelihood = -np.sum(Y * np.log(lam) - lam)\n",
    "        return neg_log_likelihood\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        opt_loss = lambda coeffs: self.loss(X, Y, coeffs)\n",
    "        initial_arguments = np.zeros(X.shape[1] + 1)  # Starting with 0 as initial guess\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments, method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        if self.coeffs is None:\n",
    "            raise ValueError(\"The model is not fitted yet.\")\n",
    "        return np.exp(np.dot(X, self.coeffs[:-1]) + self.coeffs[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "problem2_X_train_standardized = scaler.fit_transform(problem2_X_train)\n",
    "problem2_X_test_standardized = scaler.transform(problem2_X_test)\n",
    "problem2_model.fit(problem2_X_train_standardized, problem2_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09980239038205121"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Assuming you have predictions and actual values for the test data\n",
    "predictions = problem2_model.predict(problem2_X_test)\n",
    "actual_values = problem2_y_test\n",
    "\n",
    "# Calculate MAE\n",
    "MAE = mean_absolute_error(actual_values, predictions)\n",
    "\n",
    "problem2_metric = MAE\n",
    "\n",
    "# Constants for Hoeffding's inequality\n",
    "a = 0  # Minimum error\n",
    "b = 70  # Maximum error, roughly 5 days between visits as a maximum value\n",
    "n = len(problem2_y_test)  # Number of samples in the test set\n",
    "delta = 0.05  # Confidence level (95%)\n",
    "\n",
    "\n",
    "\n",
    "# Compute the Hoeffding bound (t)\n",
    "t = np.sqrt((b - a) ** 2 * np.log(2 / delta) / (2 * n))\n",
    "\n",
    "# Confidence interval for the MAE\n",
    "l_edge = max(problem2_metric - t, a)  # Ensuring the lower edge is at least 'a'\n",
    "r_edge = min(problem2_metric + t, b)\n",
    "\n",
    "# Put the confidence interval in the variable below\n",
    "problem2_interval = (l_edge, r_edge)\n",
    "\n",
    "# Assign the MAE to the variable\n",
    "problem2_metric = problem2_metric\n",
    "problem2_interval\n",
    "problem2_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Random variable generation and transformation\n",
    "\n",
    "The purpose of this problem is to show that you can implement your own sampler, this will be built in the following three steps:\n",
    "\n",
    "1. [2p] Implement a Linear Congruential Generator where you tested out a good combination (a large $M$ with $a,b$ satisfying the Hull-Dobell (Thm 6.8)) of parameters. Follow the instructions in the code block.\n",
    "2. [2p] Using a generator construct random numbers from the uniform $[0,1]$ distribution.\n",
    "3. [4p] Using a uniform $[0,1]$ random generator, generate samples from \n",
    "\n",
    "$$p_0(x) = \\frac{\\pi}{2}|\\sin(2\\pi x)|, \\quad x \\in [0,1] \\enspace .$$\n",
    "\n",
    "Using the **Accept-Reject** sampler (**Algorithm 1** in TFDS notes) with sampling density given by the uniform $[0,1]$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem3_LCG(size=None, seed=0):\n",
    "    \"\"\"\n",
    "    A linear congruential generator that generates pseudo random numbers according to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    seed : the starting point of the LCG, i.e., u0 in the notes.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    out : a list of the pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters for the LCG, these should satisfy Hull-Dobell Theorem\n",
    "    a = 16807  # Multiplier\n",
    "    M = 2**31 - 1  # Modulus\n",
    "    c = 0  # Increment\n",
    "    \n",
    "    # Initialize the state (seed)\n",
    "    state = seed\n",
    "    \n",
    "    # List to hold the pseudorandom numbers\n",
    "    out = []\n",
    "    \n",
    "    # Generate pseudorandom numbers up to the specified size\n",
    "    for _ in range(size if size is not None else 1):\n",
    "        # Update the state using the LCG formula\n",
    "        state = (a * state + c) % M\n",
    "        # Append the state to the list after normalizing\n",
    "        out.append(state / M)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem3_uniform(generator=None, period=1, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator and produces samples from the uniform [0,1] distribution according\n",
    "    to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of type generator(size, seed) that produces pseudo random numbers\n",
    "                in the range {0,1,...,period-1}\n",
    "    period    : the period of the generator\n",
    "    seed      : the seed to be used in the generator provided\n",
    "    size      : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the uniform pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate pseudo random numbers with the given generator\n",
    "    random_numbers = generator(size=size, seed=seed)\n",
    "    \n",
    "    # Normalize these numbers to the range [0,1]\n",
    "    uniform_random_numbers = [number / period for number in random_numbers]\n",
    "    \n",
    "    return uniform_random_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def problem3_accept_reject(uniformGenerator=None, n_iterations=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator that produces uniform pseudo random [0,1] numbers \n",
    "    and produces samples from (pi/2)*abs(sin(x*2*pi)) using an Accept-Reject\n",
    "    sampler with the uniform distribution as the proposal distribution.\n",
    "    Runs n_iterations\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    uniformGenerator : a function that produces uniform pseudo random\n",
    "    numbers from [0,1]\n",
    "    seed : the seed to be used in the uniform generator provided\n",
    "    n_iterations : an integer denoting how many attempts should be made in the accept-reject sampler\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the pseudo random numbers with the specified distribution\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)  # Set the seed for reproducibility\n",
    "    samples = []\n",
    "    M = np.pi / 2  # The bound for the accept-reject criterion\n",
    "\n",
    "    while len(samples) < n_iterations:\n",
    "        # Sample from the uniform distribution using the provided generator\n",
    "        x = uniformGenerator(size=1, seed=np.random.randint(0, 10000))[0]\n",
    "        \n",
    "        # Calculate the probability of accepting the sample\n",
    "        f_x = (np.pi / 2) * abs(np.sin(x * 2 * np.pi))\n",
    "        u = uniformGenerator(size=1, seed=np.random.randint(0, 10000))[0]  # Uniform random number for acceptance\n",
    "        \n",
    "        # Accept the sample with probability f(x)/(M*g(x))\n",
    "        if u < f_x / M:\n",
    "            samples.append(x)\n",
    "    \n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 2, PROBLEM 3\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCG output: [7.826369259425611e-06, 0.13153778814316625, 0.7556053221950332, 0.4586501319234493, 0.5327672374121692, 0.21895918632809036, 0.04704461621448613, 0.678864716868319, 0.6792964058366122, 0.9346928959408276]\n",
      "Uniform sampler [3.644437185986921e-15, 6.125205578488219e-11, 3.51856147193764e-10, 2.1357561095479172e-10, 2.4808907772426417e-10, 1.0196081662087291e-10, 2.190685655753733e-11, 3.1612101811191066e-10, 3.163220389526963e-10, 4.3525029736388376e-10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"LCG output: %s\" % problem3_LCG(size=10, seed=1))\n",
    "\n",
    "# Set the period to the modulus used in your LCG (replace 2**31 - 1 with your modulus if different)\n",
    "period = 2**31 - 1\n",
    "\n",
    "# Print the output of the uniform sampler\n",
    "print(\"Uniform sampler %s\" % problem3_uniform(generator=problem3_LCG, period=period, size=10, seed=1))\n",
    "\n",
    "# Define the uniform_sampler function using a lambda expression\n",
    "uniform_sampler = lambda size, seed: problem3_uniform(generator=problem3_LCG, period=period, size=size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept-Reject sampler [0.34681819919543666, 0.6840807597768621, 0.7112329216829939, 0.4472134383484645, 0.4306555016160535, 0.7362574515465967, 0.8064626626086779, 0.3982697025447973, 0.9070912163239052, 0.09034095270802844, 0.7793670805766362, 0.30161521354562826, 0.3506308489160106, 0.742923087744433, 0.5808862932227294, 0.6420041783046236, 0.03564764807021392, 0.7818439804824748, 0.7938147365943296, 0.8392775084388612]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If however you did not manage to implement either part 1 or part 2 but still want to check part 3, you can run the code below\n",
    "\n",
    "def testUniformGenerator(size,seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    return [random.uniform(0,1) for s in range(size)]\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem3_accept_reject(uniformGenerator=testUniformGenerator, n_iterations=20, seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "lx_assignment_number": 2,
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
